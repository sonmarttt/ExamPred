{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T15:04:26.273925Z",
     "start_time": "2025-01-11T15:04:23.379364Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, roc_auc_score\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "##df = pd.read_csv(\"C:/Users/sonam/PycharmProjects/ExamPred/kaggle/input/students-exam-scores/Expanded_data_with_more_features.csv\")\n",
    "df = pd.read_csv(\"C:/Users/tabas/OneDrive-VanierCollege/Documents/GitHub/ExamPred/kaggle/input/students-exam-scores/Expanded_data_with_more_features.csv\")\n",
    "df.info() \n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30641 entries, 0 to 30640\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           30641 non-null  int64  \n",
      " 1   Gender               30641 non-null  object \n",
      " 2   EthnicGroup          28801 non-null  object \n",
      " 3   ParentEduc           28796 non-null  object \n",
      " 4   LunchType            30641 non-null  object \n",
      " 5   TestPrep             28811 non-null  object \n",
      " 6   ParentMaritalStatus  29451 non-null  object \n",
      " 7   PracticeSport        30010 non-null  object \n",
      " 8   IsFirstChild         29737 non-null  object \n",
      " 9   NrSiblings           29069 non-null  float64\n",
      " 10  TransportMeans       27507 non-null  object \n",
      " 11  WklyStudyHours       29686 non-null  object \n",
      " 12  MathScore            30641 non-null  int64  \n",
      " 13  ReadingScore         30641 non-null  int64  \n",
      " 14  WritingScore         30641 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(10)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T15:04:26.376502Z",
     "start_time": "2025-01-11T15:04:26.277927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#1. Check and Clean Data\n",
    "# Convert 'NrSiblings' to integer\n",
    "df['NrSiblings'] = df['NrSiblings'].astype(pd.Int64Dtype())\n",
    "\n",
    "# Check unique values in each column\n",
    "for column in df.columns:\n",
    "    print(f\"{column}: {df[column].unique()}\")\n",
    "\n",
    "# Check null values\n",
    "print(\"\\nNull Values in Columns:\")\n",
    "print(df.isnull().sum())"
   ],
   "id": "50d957e813f79eed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  43  44  45  47  49  50  51  52  53  54  55  56  57\n",
      "  58  59  61  62  64  65  66  67  68  69  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  91  92  93  94  96  97  98\n",
      "  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116\n",
      " 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134\n",
      " 135 136 137 138 139 140 141 142 143 144 145 148 149 150 152 153 154 155\n",
      " 156 157 158 159 160 161 162 163 164 165 166 167 168 170 171 172 173 174\n",
      " 175 176 177 178 179 180 181 182 183 185 186 187 188 189 190 191 192 193\n",
      " 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211\n",
      " 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229\n",
      " 230 231 232 233 234 235 236 237 238 239 240 241 243 244 245 246 247 248\n",
      " 249 250 251 252 253 254 255 256 257 260 261 262 263 264 265 266 267 268\n",
      " 269 270 271 272 273 274 275 276 277 278 279 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 315 316 317 318 319 320 321 322 323 324\n",
      " 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n",
      " 343 344 345 346 347 349 350 351 352 353 354 355 356 357 359 360 361 362\n",
      " 363 364 365 366 367 368 369 370 371 372 373 374 376 377 378 379 380 381\n",
      " 382 383 384 385 386 387 388 389 390 391 392 393 394 396 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 414 415 416 417 418 419 421\n",
      " 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439\n",
      " 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457\n",
      " 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475\n",
      " 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493\n",
      " 494 495 496 497 499 500 501 502 503 504 505 506 508 509 510 511 512 513\n",
      " 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531\n",
      " 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549\n",
      " 550 551 552 553 554 555 557 558 559 560 561 562 563 564 565 566 567 568\n",
      " 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 586 587 588\n",
      " 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606\n",
      " 607 608 609 610 611 612 614 615 616 617 618 619 620 621 622 623 624 625\n",
      " 626 627 628 629 630 631 632 633 635 637 638 639 640 641 642 643 644 645\n",
      " 646 647 648 649 650 651 652 653 654 655 656 657 658 659 661 662 663 664\n",
      " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 682 683\n",
      " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
      " 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719\n",
      " 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737\n",
      " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
      " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
      " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
      " 792 793 794 795 796 797 798 799 800 803 804 805 806 807 808 809 810 811\n",
      " 812 813 814 815 817 818 819 820 822 824 825 826 827 829 830 831 832 834\n",
      " 835 836 837 838 840 841 842 843 844 845 846 848 849 850 851 852 853 854\n",
      " 855 856 857 858 859 860 861 862 863 864 865 867 868 869 870 872 873 874\n",
      " 875 876 877 878 879 880 881 882 883 884 885 886 888 889 890 891 892 893\n",
      " 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911\n",
      " 912 913 914 915 916 917 918 919 920 922 923 924 925 926 927 928 929 931\n",
      " 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949\n",
      " 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967\n",
      " 968 969 970 971 972 973 974 977 978 979 980 981 982 983 984 985 986 987\n",
      " 988 989 990 991 992 993 994 995 996 997 998 999  29  46  48  60  63  70\n",
      "  90  95 146 151 169 184 242 258 259 280 314 348 358 375 395 397 413 420\n",
      " 498 507 556 584 585 613 634 636 660 681 801 816 821 823 833 839 847 866\n",
      " 871 887 921 930 975 976  42 147 802 828]\n",
      "Gender: ['female' 'male']\n",
      "EthnicGroup: [nan 'group C' 'group B' 'group A' 'group D' 'group E']\n",
      "ParentEduc: [\"bachelor's degree\" 'some college' \"master's degree\" \"associate's degree\"\n",
      " 'high school' 'some high school' nan]\n",
      "LunchType: ['standard' 'free/reduced']\n",
      "TestPrep: ['none' nan 'completed']\n",
      "ParentMaritalStatus: ['married' 'single' 'widowed' nan 'divorced']\n",
      "PracticeSport: ['regularly' 'sometimes' 'never' nan]\n",
      "IsFirstChild: ['yes' 'no' nan]\n",
      "NrSiblings: <IntegerArray>\n",
      "[3, 0, 4, 1, <NA>, 2, 5, 7, 6]\n",
      "Length: 9, dtype: Int64\n",
      "TransportMeans: ['school_bus' nan 'private']\n",
      "WklyStudyHours: ['< 5' '5 - 10' '> 10' nan]\n",
      "MathScore: [ 71  69  87  45  76  73  85  41  65  37  58  40  66  80  48  88  18  46\n",
      "  50  42  74  75  70  63  56  97  81  51  77  53  59  60  67  82  54  33\n",
      "  84  52  61   0  39  62  64  47  44  28  49  57  27  68  79 100  72  98\n",
      "  55  90  86  89  21  96  91  99  83  35  43  93  78  94  36  29  23  92\n",
      "  26  38  95  30  32   8  34  31  25  22  17  20  16  19  24  15  11  12\n",
      "  13   9  10   7  14]\n",
      "ReadingScore: [ 71  90  93  56  78  84  43  64  59  54  52  82  73  53  75  89  32  42\n",
      "  69  76  70  72  65  87  81  91  60  74  55  68  45  86  41  17  39  61\n",
      "  58  62  37  51  48  25  79  50  47  38  80  34  77  46  66  67  92  44\n",
      "  88 100  63  99  83  94  57  49  36  85  40  28  97  23  33  98  95  31\n",
      "  24  29  96  35  26  21  30  18  15  11  20  19  16  22  27  12  10  14]\n",
      "WritingScore: [ 74  88  91  42  75  79  89  39  68  50  52  43  71  58  78  86  28  47\n",
      "  63  70  51  80  76  53  65  72  61  66  38  82  85  60  90  69  67  55\n",
      "  77  48  87  49  10  34  59  37  57  64  54  40  21  83  73  45  33  36\n",
      "  94  62 100  99  95  56  41  27  81  98  46  44  19  26  31  84  97  93\n",
      "  96  92  15  30  32  23  35  29  17  25  24  20   6  22  14  18  16  12\n",
      "   9  13   4]\n",
      "\n",
      "Null Values in Columns:\n",
      "Unnamed: 0                0\n",
      "Gender                    0\n",
      "EthnicGroup            1840\n",
      "ParentEduc             1845\n",
      "LunchType                 0\n",
      "TestPrep               1830\n",
      "ParentMaritalStatus    1190\n",
      "PracticeSport           631\n",
      "IsFirstChild            904\n",
      "NrSiblings             1572\n",
      "TransportMeans         3134\n",
      "WklyStudyHours          955\n",
      "MathScore                 0\n",
      "ReadingScore              0\n",
      "WritingScore              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T15:04:30.352672Z",
     "start_time": "2025-01-11T15:04:30.199288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#2. Impute Missing Values\n",
    "# Fill missing values for categorical columns with mode\n",
    "categorical_cols = ['EthnicGroup', 'WklyStudyHours', 'ParentEduc', \n",
    "                    'ParentMaritalStatus', 'IsFirstChild', \n",
    "                    'PracticeSport', 'TestPrep', 'TransportMeans']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Fill missing numerical values\n",
    "df['NrSiblings'] = df['NrSiblings'].interpolate()\n",
    "\n",
    "# Confirm no null values remain\n",
    "print(\"\\nAfter Imputation:\")\n",
    "print(df.isnull().sum())\n"
   ],
   "id": "c204dc00f2c8ca2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Imputation:\n",
      "Unnamed: 0             0\n",
      "Gender                 0\n",
      "EthnicGroup            0\n",
      "ParentEduc             0\n",
      "LunchType              0\n",
      "TestPrep               0\n",
      "ParentMaritalStatus    0\n",
      "PracticeSport          0\n",
      "IsFirstChild           0\n",
      "NrSiblings             0\n",
      "TransportMeans         0\n",
      "WklyStudyHours         0\n",
      "MathScore              0\n",
      "ReadingScore           0\n",
      "WritingScore           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T15:00:38.836555Z",
     "start_time": "2025-01-11T15:00:38.753418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#3. Map Binary and Ordinal Variables\n",
    "# Map binary and ordinal features\n",
    "binary_mappings = {\n",
    "    'Gender': {'female': 0, 'male': 1},\n",
    "    'TestPrep': {'none': 0, 'completed': 1},\n",
    "    'IsFirstChild': {'no': 0, 'yes': 1},\n",
    "    'TransportMeans': {'private': 0, 'school_bus': 1}\n",
    "}\n",
    "\n",
    "df.replace(binary_mappings, inplace=True)\n",
    "\n",
    "# Map ordinal features (if any, e.g., study hours)\n",
    "study_hours_mapping = {'< 5': 'Less than 5 h', '5 - 10': 'Between 5-10 h', '> 10': 'More than 10 h'}\n",
    "df['WklyStudyHours'] = df['WklyStudyHours'].map(study_hours_mapping)\n"
   ],
   "id": "d746335556e95a6c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T15:02:47.109863Z",
     "start_time": "2025-01-11T15:02:33.553672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#4. Encode Categorical Variables\n",
    "# One-hot encode categorical variables\n",
    "categorical_features = ['EthnicGroup', 'LunchType', 'ParentMaritalStatus', 'WklyStudyHours', 'ParentEduc']\n",
    "df = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Confirm final dataframe structure\n",
    "print(\"\\nFinal Dataset Columns:\")\n",
    "print(df.columns)\n"
   ],
   "id": "8beec2c4539638cb",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['EthnicGroup', 'LunchType', 'ParentMaritalStatus', 'WklyStudyHours'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#4. Encode Categorical Variables\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# One-hot encode categorical variables\u001B[39;00m\n\u001B[0;32m      3\u001B[0m categorical_features \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEthnicGroup\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLunchType\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mParentMaritalStatus\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWklyStudyHours\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mParentEduc\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m----> 4\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mget_dummies(df, columns\u001B[38;5;241m=\u001B[39mcategorical_features, drop_first\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Confirm final dataframe structure\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mFinal Dataset Columns:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:169\u001B[0m, in \u001B[0;36mget_dummies\u001B[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001B[0m\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput must be a list-like for parameter `columns`\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 169\u001B[0m     data_to_encode \u001B[38;5;241m=\u001B[39m data[columns]\n\u001B[0;32m    171\u001B[0m \u001B[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck_len\u001B[39m(item, name: \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4106\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[0;32m   4107\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 4108\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39m_get_indexer_strict(key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   4110\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[0;32m   4111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   6197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6198\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 6200\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001B[0;32m   6202\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   6203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   6204\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   6249\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6251\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m-> 6252\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['EthnicGroup', 'LunchType', 'ParentMaritalStatus', 'WklyStudyHours'] not in index\""
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T15:02:47.117259Z",
     "start_time": "2025-01-11T15:02:47.117259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Visualize Data Distributions\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for column in df.columns:\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        sns.histplot(df[column], kde=False, bins=30, color='blue')\n",
    "        plt.title(f'Distribution of {column}', fontsize=16)\n",
    "    else:\n",
    "        df[column].value_counts().plot(kind='bar', color='green')\n",
    "        plt.title(f'Value Counts of {column}', fontsize=12)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n"
   ],
   "id": "b9646704ab786cc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#6. Scaling and Splitting Data \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('MathScore', axis=1)\n",
    "y = df['MathScore']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data Preprocessing Complete.\")\n"
   ],
   "id": "e5bf19e8ad297fc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T15:01:01.354014Z",
     "start_time": "2025-01-11T15:01:01.354014Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1d739cd06889bc3f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
